{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytz,os\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import LongType \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import countDistinct, row_number\n",
    "from pyspark.sql import SQLContext, HiveContext\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqlContext = SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.text(\"idunidade_operacional\", \"3\")\n",
    "dbutils.widgets.text(\"idcidade\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_operacional = dbutils.widgets.get(\"idunidade_operacional\") \n",
    "cidade = dbutils.widgets.get(\"idcidade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para geração de listas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "verifica a partir de ordens de servico de religacao quem foi religado no final de semana\n",
    "\"\"\"\n",
    "\n",
    "def verifica_religados_final_semana (nsc_paracorte):\n",
    "  \n",
    "  df_cortes_religacoes = spark.read.table('transient.religacoes_modelo')\n",
    "  df_cortes_religacoes = df_cortes_religacoes.where((col('idcidade')== cidade) & (col('idunidadeoperacional') == u_operacional))\n",
    "  \n",
    "  df_cortes_religacoes_fds = df_cortes_religacoes.where(datediff(current_date(), col('datahoraterminoexecucao'))<=2)\n",
    "\n",
    "  nsc_paracorte_religados =  nsc_paracorte.alias('paracortar').join(df_cortes_religacoes_fds.alias('rel_fds'),\\\n",
    "                                                                    [nsc_paracorte.cdc_proc_aberto == df_cortes_religacoes_fds.idligacao],\"LEFT\")\\\n",
    "                                                              .select('paracortar.*', 'rel_fds.datahoraterminoexecucao')\n",
    "  \n",
    "  nsc_para_corte = nsc_paracorte_religados.where(col('datahoraterminoexecucao').isNull())\n",
    "  nsc_religados = nsc_paracorte_religados.where(col('datahoraterminoexecucao').isNotNull())\n",
    "\n",
    "  return nsc_para_corte.drop('datahoraterminoexecucao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "verifica quais ligacoes estao com ordem de corte aberta \n",
    "\"\"\"\n",
    "\n",
    "def verifica_ordens_corte_abertas(nsc_paracorte):\n",
    "  \n",
    "  df_ordens_corte_abertas  = spark.read.table('transient.cortes_modelo')\n",
    "  \n",
    "  df_ordens_corte_abertas = df_ordens_corte_abertas.where((col('idstatusordemservico')==1)\\\n",
    "                                                          &(col('datahoraterminoexecucao').isNull())\\\n",
    "                                                          &(datediff(current_date(), col('datahoraabertura'))<=3)\\\n",
    "                                                          &(datediff(current_date(), col('datahoraabertura'))>=0))\n",
    "  \n",
    "  paracortar_osaberta = nsc_paracorte.alias('paracortar').join(df_ordens_corte_abertas.alias('os'), \\\n",
    "                                                               [nsc_paracorte.cdc_proc_aberto == df_ordens_corte_abertas.idligacao], \"LEFT\")\\\n",
    "                                                          .select('paracortar.*', 'os.idligacao')\n",
    "  \n",
    "  return paracortar_osaberta.where(col('idligacao').isNull()).drop('idligacao') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "verifica quais ligacoes da lista correspondem aos moradores atuais da ligacao\n",
    "\"\"\"\n",
    "def get_cdcs_id_corrente(lista_debitos):\n",
    "    listas_debitos = lista_debitos.withColumn('cliente_devedor_diferente',\\\n",
    "                                            when(col(\"cadas_idclienteinquilino\").isNull(),0)\\\n",
    "                                             .otherwise(\\\n",
    "                                                        when(col(\"preds_idclienteinquilino\") == col(\"cadas_idclienteinquilino\"), 0)\\\n",
    "                                                        .otherwise(1)))\n",
    " \n",
    "    debitos_usuario_antigo = listas_debitos.where(col(\"cliente_devedor_diferente\") == 1)\n",
    "    debitos_usuario_corrente = listas_debitos.where(col(\"cliente_devedor_diferente\") == 0)\n",
    "    return (debitos_usuario_antigo, debitos_usuario_corrente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de Geração de lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A  função a seguir constroi a lista de ligações aptas para serem cortadas\n",
    "A partir de Predições e processos pendentes, identificam-se os Non-Self-Cures\n",
    "que tem debito pendente e um processo com data apta para corte \n",
    "\"\"\"\n",
    "\n",
    "def get_nao_self_cures_paracortar(df_predictions):\n",
    "  \n",
    "  # COLETANDO TODOS OS PROCESSOS ABERTOS COM DEBITOS PENDENTES\n",
    "  processos_abertos = spark.read.table('transient.processos_modelo')\\\n",
    "  .where((col('status_processo') == 'P')\\\n",
    "         & (col('data_pagamento').isNull())\\\n",
    "         & (col('data_parcelamento').isNull())\\\n",
    "         & (col('id_situacao_fatura') == 1)\\\n",
    "         & (datediff(current_date(), col('data_apto_corte'))>1)\\\n",
    "         & (col('id_objetivo_processo_corte') ==2))\\\n",
    "  .withColumnRenamed('id_processo_corte', 'id_proc')\\\n",
    "  .withColumnRenamed('cdc', 'cdc_proc_aberto')\\\n",
    "  .withColumnRenamed('fatura_id', 'fatura_proc_aberto')\\\n",
    "  .withColumnRenamed('status_processo', 'status_p')\\\n",
    "  .withColumnRenamed('data_pagamento', 'data_pag')\\\n",
    "  .withColumnRenamed('data_parcelamento', 'data_parc')\\\n",
    "  .withColumnRenamed('id_situacao_fatura', 'situacao_fat')\\\n",
    "  .withColumnRenamed('data_corte_prevista', 'data_c_prev')\\\n",
    "  .withColumnRenamed('data_apto_corte', 'd_apto_corte')\\\n",
    "  .withColumnRenamed('valor', 'valor_proc_aberto')\n",
    "  \n",
    "  ##########  RETIRANDO OS QUE JA ESTAO CORTADOS - VIA SITUACAO_COBRANCA ###########\n",
    "  \n",
    "  df_cadastros = spark.read.table('transient.cadastros_modelo')\n",
    "  processos_abertos = processos_abertos.alias('p').join(df_cadastros.alias('c'),\\\n",
    "                                                        [processos_abertos.cdc_proc_aberto == df_cadastros.cdc], 'LEFT')\\\n",
    "                                                  .select('p.*', 'c.situacao_cobranca')\n",
    "  processos_abertos = processos_abertos.where(col('situacao_cobranca')!= \"CORTADO\")\n",
    "  \n",
    "  ##################################################################################\n",
    "  \n",
    "  ################### INCORPORANDO AS PREDICOES #####################################\n",
    "  df_preds_processo_aberto = processos_abertos.alias('abertos')\\\n",
    "  .join(df_predictions.alias('preds'), [processos_abertos.cdc_proc_aberto == df_predictions.cdc,\\\n",
    "                                        processos_abertos.id_proc == df_predictions.id_processo_corte,\\\n",
    "                                        processos_abertos.fatura_proc_aberto == df_predictions.fatura_id], 'LEFT')\\\n",
    "  .select('preds.*', 'abertos.id_proc', 'abertos.cdc_proc_aberto',\\\n",
    "          'abertos.fatura_proc_aberto', 'abertos.valor_proc_aberto',\\\n",
    "          'abertos.status_p', 'abertos.situacao_fat', 'abertos.data_pag',\\\n",
    "          'abertos.data_parc', 'abertos.data_c_prev', 'abertos.d_apto_corte')\n",
    "  ####################################################################################\n",
    "  \n",
    "\n",
    "  ####################### IDENTIFICAR CDCS NON SELF CURES ############################\n",
    "  ### CONTROLAR OS SELF CURES APENAS NO PERIODO DOS 20 DIAS APOIX A DATA PREVISTA DE CORTE\n",
    "  df_preds = df_preds_processo_aberto.withColumn('prediction_integer', when(col('prediction') == 'SELF_CURE',\\\n",
    "                                                                            when(datediff(current_date(), col('d_apto_corte'))>20,1)\\\n",
    "                                                                            .otherwise(0))\\\n",
    "                                                 .otherwise(when(col('prediction') == 'NON_SELF_CURE', 1)\\\n",
    "                                                            .otherwise(when(datediff(current_date(), col('d_apto_corte'))>20,1).otherwise(0))))\\\n",
    "  .withColumn('prediction_integer_cdc', sum(col('prediction_integer')).over(Window.partitionBy('cdc_proc_aberto')))\\\n",
    "  .withColumn('prediction_final_cdc', when(col('prediction_integer_cdc')>0, 'NON_SELF_CURE'))\n",
    "  #######################################################################################\n",
    "  \n",
    "  ############### SELECIONAMOS CDCs NON SELF CURES #########################################\n",
    "  df_preds = df_preds.where(col('prediction_integer_cdc') >= 1)\n",
    "  df_preds = df_preds.dropDuplicates(['cdc_proc_aberto', 'fatura_proc_aberto', 'data_pag', 'data_parc', 'situacao_fat'])\n",
    "  ##########################################################################################\n",
    "  \n",
    "  ############### CALCULANDO O TOTAL DE DEBITO e TOTAL DE FATURAS DO CDC NO PROCESSO ########\n",
    "  procs_preds1 = df_preds.groupBy('id_proc', 'cdc_proc_aberto').\\\n",
    "                                     agg(max('prediction_final_cdc').alias('prediction_final_cdc'),\\\n",
    "                                         max(col('d_apto_corte')).alias('d_apto_corte'),\\\n",
    "                                         round(sum(when(col('valor_proc_aberto').isNull(), 0)\\\n",
    "                                                   .otherwise(col('valor_proc_aberto'))),2).alias('total_debito_cdc_processo'),\\\n",
    "                                         countDistinct(col('fatura_proc_aberto')).alias('total_faturas_cdc_processo'))\n",
    "  ############################################################################################\n",
    "  \n",
    "  ##########  CALCULANDO TOTAL DE DEBITO DO CDC AO LONGO DOS PROCESSOS ABERTOS ###############\n",
    "  procs_preds_viaveis_corte1 = procs_preds1.groupBy('cdc_proc_aberto').\\\n",
    "                               agg(max('prediction_final_cdc').alias('target_final'),\\\n",
    "                                   max(col('d_apto_corte')).alias('data_apto_corte'),\\\n",
    "                                   round(sum(col('total_debito_cdc_processo')),2).alias('total_debito_cdc'),\\\n",
    "                                   sum(col('total_faturas_cdc_processo')).alias('total_faturas_debidas_cdc'))\n",
    "  #############################################################################################\n",
    "\n",
    "  \n",
    "  ################### FILTRANDO LIGACOES QUE TEM DEBITO MAIOR A 30 ############################\n",
    "  procs_preds_viaveis_corte1 = procs_preds_viaveis_corte1.where(col('total_debito_cdc') >= 30)\n",
    "  \n",
    "  ########################## ADICIONANDO COLUNA DO VALOR HIT ##################################\n",
    "  procs_preds_viaveis_corte1 = procs_preds_viaveis_corte1\\\n",
    "                                            .withColumn('hit_cdc', round(col('total_debito_cdc')/col('total_faturas_debidas_cdc'),2))\n",
    "  \n",
    "  ## SEPARANDO LIGACOES COM DEBITO MENOR A 30 REAIS, CASO NECESSARIO EMITIR EM LISTA SEPARADA ##\n",
    "  debitos_menos_de_10 = procs_preds_viaveis_corte1.where(col('total_debito_cdc') < 30)\n",
    "  \n",
    "  ################ VERIFICACOES LIGACOES RELIGADAS NO FINAL DE SEMANA #########################\n",
    "  if (datetime.today().weekday() == 0):\n",
    "    print ('E segunda')\n",
    "    procs_preds_viaveis_corte1 = verifica_religados_final_semana(procs_preds_viaveis_corte1)\n",
    "    \n",
    "  procs_preds_viaveis_corte2_ = verifica_ordens_corte_abertas(procs_preds_viaveis_corte1)\n",
    "  \n",
    "  \n",
    "  ### JOIN PARA INCORPORAR INFORMACOES DE GRUPO, SETOR, ROTA DE LEITURA, LOGRADOURO ###########\n",
    "  para_cortar = procs_preds_viaveis_corte2_.alias('vc').join(df_cadastros.alias('c'),\\\n",
    "                                                             procs_preds_viaveis_corte2_.cdc_proc_aberto == df_cadastros.cdc, \"LEFT\")\\\n",
    "                                                       .select('c.grupo_leitura_id', 'c.grupo_leitura', 'c.setor_leitura',\\\n",
    "                                                               'c.logradouro_id', 'c.logradouro','vc.*')\n",
    "  \n",
    "  para_cortar_final = para_cortar.withColumnRenamed('logradouro', 'logradouro_completo')\\\n",
    "  .withColumn('grupo_setor', concat(col('grupo_leitura_id'), lit('-'), col('setor_leitura')))\\\n",
    "  .withColumnRenamed('cdc_proc_aberto', 'cdc')\n",
    "  #############################################################################################\n",
    "  \n",
    "  return para_cortar_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A  função a seguir constroi a lista de ligações Self-Cures, cortadas ou não\n",
    "\"\"\"\n",
    "\n",
    "def get_self_cures(df_predictions):\n",
    "  \n",
    "  # COLETANDO TODOS OS PROCESSOS ABERTOS COM DEBITOS PENDENTES\n",
    "  processos_abertos = spark.read.table('transient.processos_modelo')\\\n",
    "  .where((col('status_processo') == 'P')\\\n",
    "         & (col('data_pagamento').isNull())\\\n",
    "         & (col('data_parcelamento').isNull())\\\n",
    "         & (col('id_situacao_fatura') == 1)\\\n",
    "         & (datediff(current_date(), col('data_apto_corte'))>1)\\\n",
    "         & (col('id_objetivo_processo_corte') ==2))\\\n",
    "  .withColumnRenamed('id_processo_corte', 'id_proc')\\\n",
    "  .withColumnRenamed('cdc', 'cdc_proc_aberto')\\\n",
    "  .withColumnRenamed('fatura_id', 'fatura_proc_aberto')\\\n",
    "  .withColumnRenamed('status_processo', 'status_p')\\\n",
    "  .withColumnRenamed('data_pagamento', 'data_pag')\\\n",
    "  .withColumnRenamed('data_parcelamento', 'data_parc')\\\n",
    "  .withColumnRenamed('id_situacao_fatura', 'situacao_fat')\\\n",
    "  .withColumnRenamed('data_corte_prevista', 'data_c_prev')\\\n",
    "  .withColumnRenamed('data_apto_corte', 'd_apto_corte')\\\n",
    "  .withColumnRenamed('valor', 'valor_proc_aberto')\n",
    "  \n",
    "  ##########  RETIRANDO OS QUE JA ESTAO CORTADOS - VIA SITUACAO_COBRANCA ###########\n",
    "  \n",
    "  df_cadastros = spark.read.table('transient.cadastros_modelo')\n",
    "  processos_abertos = processos_abertos.alias('p').join(df_cadastros.alias('c'),\\\n",
    "                                                        [processos_abertos.cdc_proc_aberto == df_cadastros.cdc], 'LEFT')\\\n",
    "                                                  .select('p.*', 'c.situacao_cobranca')\n",
    "  processos_abertos = processos_abertos.where(col('situacao_cobranca')!= \"CORTADO\")\n",
    "  \n",
    "  ##################################################################################\n",
    "  \n",
    "  ################### INCORPORANDO AS PREDICOES #####################################\n",
    "  df_preds_processo_aberto = processos_abertos.alias('abertos')\\\n",
    "  .join(df_predictions.alias('preds'), [processos_abertos.cdc_proc_aberto == df_predictions.cdc,\\\n",
    "                                        processos_abertos.id_proc == df_predictions.id_processo_corte,\\\n",
    "                                        processos_abertos.fatura_proc_aberto == df_predictions.fatura_id], 'LEFT')\\\n",
    "  .select('preds.*', 'abertos.id_proc', 'abertos.cdc_proc_aberto',\\\n",
    "          'abertos.fatura_proc_aberto', 'abertos.valor_proc_aberto',\\\n",
    "          'abertos.status_p', 'abertos.situacao_fat', 'abertos.data_pag',\\\n",
    "          'abertos.data_parc', 'abertos.data_c_prev', 'abertos.d_apto_corte')\n",
    "  ####################################################################################\n",
    "  \n",
    "\n",
    "  ####################### IDENTIFICAR CDCS SELF CURES ############################\n",
    "  ### CONTROLAR OS SELF CURES APENAS NO PERIODO DOS 20 DIAS APOIX A DATA PREVISTA DE CORTE\n",
    "  df_preds = df_preds_processo_aberto.withColumn('prediction_integer', when(col('prediction') == 'SELF_CURE',\\\n",
    "                                                                            when(datediff(current_date(), col('d_apto_corte'))>20,1)\\\n",
    "                                                                            .otherwise(0))\\\n",
    "                                                 .otherwise(when(col('prediction') == 'NON_SELF_CURE', 1)\\\n",
    "                                                            .otherwise(when(datediff(current_date(), col('d_apto_corte'))>20,1).otherwise(0))))\\\n",
    "  .withColumn('prediction_integer_cdc', sum(col('prediction_integer')).over(Window.partitionBy('cdc_proc_aberto')))\\\n",
    "  .withColumn('prediction_final_cdc', when(col('prediction_integer_cdc')>0, 'NON_SELF_CURE'))\n",
    "  #######################################################################################\n",
    "  \n",
    "  ############### SELECIONAMOS SELF CURES #########################################\n",
    "  df_preds = df_preds.where(col('prediction_integer_cdc') <= 0)\n",
    "  df_preds = df_preds.dropDuplicates(['cdc_proc_aberto', 'fatura_proc_aberto', 'data_pag', 'data_parc', 'situacao_fat'])\n",
    "  ##########################################################################################\n",
    "  \n",
    "  ############### CALCULANDO O TOTAL DE DEBITO e TOTAL DE FATURAS DO CDC NO PROCESSO ########\n",
    "  procs_preds1 = df_preds.groupBy('id_proc', 'cdc_proc_aberto').\\\n",
    "                                     agg(max('prediction_final_cdc').alias('prediction_final_cdc'),\\\n",
    "                                         max(col('d_apto_corte')).alias('d_apto_corte'),\\\n",
    "                                         round(sum(when(col('valor_proc_aberto').isNull(), 0)\\\n",
    "                                                   .otherwise(col('valor_proc_aberto'))),2).alias('total_debito_cdc_processo'),\\\n",
    "                                         countDistinct(col('fatura_proc_aberto')).alias('total_faturas_cdc_processo'))\n",
    "  ############################################################################################\n",
    "  \n",
    "  ##########  CALCULANDO TOTAL DE DEBITO DO CDC AO LONGO DOS PROCESSOS ABERTOS ###############\n",
    "  self_cures = procs_preds1.groupBy('cdc_proc_aberto').\\\n",
    "                               agg(max('prediction_final_cdc').alias('target_final'),\\\n",
    "                                   max(col('d_apto_corte')).alias('data_apto_corte'),\\\n",
    "                                   round(sum(col('total_debito_cdc_processo')),2).alias('total_debito_cdc'),\\\n",
    "                                   sum(col('total_faturas_cdc_processo')).alias('total_faturas_debidas_cdc'))\n",
    "  #############################################################################################\n",
    "\n",
    "  ########################## ADICIONANDO COLUNA DO VALOR HIT ##################################\n",
    "  self_cures = self_cures.withColumn('hit_cdc', round(col('total_debito_cdc')/col('total_faturas_debidas_cdc'),2))\n",
    "  #############################################################################################\n",
    "  \n",
    "  ### JOIN PARA INCORPORAR INFORMACOES DE GRUPO, SETOR, ROTA DE LEITURA, LOGRADOURO ###########\n",
    "  self_cures_list = self_cures.alias('sc').join(df_cadastros.alias('c'),self_cures.cdc_proc_aberto == df_cadastros.cdc, \"LEFT\")\\\n",
    "                                          .select('c.grupo_leitura_id', 'c.grupo_leitura',\\\n",
    "                                                  'c.setor_leitura', 'c.logradouro_id', 'c.logradouro','sc.*')\n",
    "  \n",
    "  self_cures_list1 = self_cures_list.withColumnRenamed('logradouro', 'logradouro_completo')\\\n",
    "  .withColumn('grupo_setor', concat(col('grupo_leitura_id'), lit('-'), col('setor_leitura')))\\\n",
    "  .withColumnRenamed('cdc_proc_aberto', 'cdc')\\\n",
    "  .withColumnRenamed('target_final', 'predicao_modelo')\\\n",
    "  .withColumn('predicao_modelo', lit('SELF_CURE'))\n",
    "  #############################################################################################\n",
    "  \n",
    " \n",
    "  return self_cures_list1.orderBy(desc(col('hit_cdc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A  função a seguir constroi a lista de preditos(Self-cures ou Nao Self-Cures) cortados a mais de 90 dias\n",
    "\"\"\"\n",
    "\n",
    "def get_cortados_mais_90_dias(df_predictions):\n",
    "  \n",
    "  df_predictions = df_predictions.withColumn('integer_prediction', when(col('prediction')== \"SELF_CURE\",0).otherwise(1))\n",
    "  window_spec_preds = Window.partitionBy('cdc')\n",
    "  df_predictions = df_predictions.withColumn('prediction_cdc', when(sum(col('integer_prediction'))\\\n",
    "                                                                    .over(window_spec_preds) > 0, 'NON_SELF_CURE')\\\n",
    "                                                               .otherwise('SELF_CURE'))\n",
    "\n",
    "  df_processos = spark.read.table('transient.processos_modelo')\n",
    "  df_cadastros = spark.read.table('transient.cadastros_modelo')\n",
    "  \n",
    "  print(df_predictions.columns)\n",
    "  \n",
    "  ############### JOIN PREDICTIONS E CADASTROS PARA TRAZER A SITUACAO DE COBRANSA = CORTADO ##########################\n",
    "  \n",
    "  df_predictions = df_predictions.alias('p').join(df_cadastros.alias('c'), [df_predictions.cdc == df_cadastros.cdc], \"LEFT\")\\\n",
    "                                            .select('p.*', 'c.situacao_cobranca')\n",
    "  \n",
    "  ####################################################################################################################\n",
    "  \n",
    "  df_predictions = df_predictions.where((col('situacao_cobranca')==\"CORTADO\"))\n",
    "  \n",
    "  procs = df_processos.dropDuplicates(['id_processo_corte', 'cdc', 'fatura_id'])\n",
    "  \n",
    "  procs1 = procs.groupBy('cdc').agg(max('data_corte').alias('data_corte_mais_recente'),\\\n",
    "                                    round(sum(col('valor')),2).alias('debito_ate_corte'),countDistinct(col('fatura_id'))\\\n",
    "                                    .alias('nro_faturas_debidas_ate_corte'))\n",
    "  \n",
    "  procs2 = procs1.alias('processos').join(df_predictions.alias('preds'),\\\n",
    "                                          procs1.cdc == df_predictions.preds_cdc, \"INNER\")\\\n",
    "                                    .select('processos.*', 'preds.prediction_cdc')\n",
    "  \n",
    "  procs2 = procs2.select('cdc', 'prediction_cdc', 'data_corte_mais_recente',\\\n",
    "                         'debito_ate_corte', 'nro_faturas_debidas_ate_corte').dropDuplicates(['cdc'])\n",
    "  \n",
    "  procs2 = procs2.where(datediff(current_date(), col('data_corte_mais_recente'))>=90)\n",
    "  \n",
    "  return procs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A  função a seguir constroi a lista para fiscalizar a partir do modelo de religacao do Vinicius\n",
    "\"\"\"\n",
    "def get_lista_parafiscalizar(n_cidade = \"\", n_unidade = \"\"):\n",
    "  \n",
    "  df_cadastros = spark.read.table('transient.cadastros_modelo')\n",
    "  \n",
    "  timezone = pytz.timezone('America/Sao_Paulo')\n",
    "  today_date = datetime.now(tz = timezone)\n",
    "  t_ano = str(today_date.year)\n",
    "  t_mes = str(today_date.month)\n",
    "  t_dia = str(today_date.day)\n",
    "  \n",
    "  if (len(t_mes)==1):\n",
    "    t_mes = \"0\"+t_mes\n",
    "  if (len(t_dia) ==1):\n",
    "    t_dia = \"0\"+t_dia\n",
    "    \n",
    "  nome_tabela_preditos_modelo = \"modelos_preditivos.religacao_\" + n_cidade + \"_preditos_\" + t_dia + \"_\" + t_mes + \"_\" + t_ano\n",
    "  \n",
    "  try:\n",
    "    tabela_preditos_religacao = spark.read.table(nome_tabela_preditos_modelo)\n",
    "  except:\n",
    "    return None\n",
    "  else:\n",
    "    tabela_preditos_religacao = tabela_preditos_religacao.alias('r').join(df_cadastros.alias('c'),\\\n",
    "                                                                        tabela_preditos_religacao.CDC == df_cadastros.cdc, \"LEFT\")\\\n",
    "                                                                  .select('r.CDC', 'c.grupo_leitura', 'c.grupo_leitura_id',\\\n",
    "                                                                          'c.setor_leitura', 'c.logradouro_id', 'c.logradouro',\\\n",
    "                                                                          'c.situacao_cobranca', 'r.DEBITO_TOTAL_FATURAS',\\\n",
    "                                                                          'r.QTD_FATURAS_PENDENTES_FATURAS', 'r.ACAO_A_REALIZAR', 'r.TARGET')\\\n",
    "                                                                  .withColumn('hit_cdc', round(col('DEBITO_TOTAL_FATURAS')/col('QTD_FATURAS_PENDENTES_FATURAS'),2))\\\n",
    "                                                                  .withColumnRenamed('logradouro', 'logradouro_completo')\\\n",
    "                                                                  .withColumnRenamed('DEBITO_TOTAL_FATURAS', 'total_debito_cdc')\\\n",
    "                                                                  .withColumnRenamed('QTD_FATURAS_PENDENTES_FATURAS','total_faturas_debidas_cdc')\\\n",
    "                                                                  .withColumnRenamed('ACAO_A_REALIZAR', 'acao_sugerida')\\\n",
    "                                                                  .withColumnRenamed('TARGET', 'probabilidade_religacao')\n",
    "    parafiscalizar = tabela_preditos_religacao.where(col('acao_sugerida') == 'FISCALIZAR')\n",
    "    return parafiscalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Aplica o modelo de religacao do Vinicius a partir de uma lista de preditos por outro modelo (Modelo Self-Cures)\n",
    "\"\"\"\n",
    "\n",
    "def aplica_modelo_preditivo_religa(df_lista, n_cidade = \"\", n_unidade = \"\"):\n",
    "  \n",
    "  timezone = pytz.timezone('America/Sao_Paulo')\n",
    "  today_date = datetime.now(tz = timezone)\n",
    "  t_ano = str(today_date.year)\n",
    "  t_mes = str(today_date.month)\n",
    "  t_dia = str(today_date.day)\n",
    "  if (len(t_mes)==1):\n",
    "    t_mes = \"0\"+t_mes\n",
    "  if (len(t_dia) ==1):\n",
    "    t_dia = \"0\"+t_dia\n",
    "  \n",
    "  nome_tabela_preditos_modelo = \"modelos_preditivos.religacao_\" + n_cidade + \"_preditos_\" + t_dia + \"_\" + t_mes + \"_\" + t_ano\n",
    "\n",
    "  try:\n",
    "    tabela_preditos_religacao = spark.read.table(nome_tabela_preditos_modelo)\n",
    "    \n",
    "  except:\n",
    "    return df_lista.withColumn('probabilidade_religacao', lit(1.0)).withColumn('acao_sugerida', lit(\"CORTAR\"))\n",
    "  \n",
    "  else:\n",
    "    tabela_preditos_religacao = tabela_preditos_religacao.where(col('acao_a_realizar') == 'CORTAR')\n",
    "    df_lista_filtrada = df_lista.alias(\"l1\").join(tabela_preditos_religacao.alias(\"l2\"), \\\n",
    "                                                  df_lista.cdc == tabela_preditos_religacao.CDC, \"inner\")\\\n",
    "                                            .select(\"l1.*\", \"l2.ACAO_A_REALIZAR\",\\\n",
    "                                                    \"l2.TARGET\")\n",
    "    \n",
    "    df_lista_filtrada = df_lista_filtrada.where(col(\"target\").isNotNull())\n",
    "    \n",
    "    df_lista_filtrada_final = df_lista_filtrada.withColumn(\"acao_sugerida\", col(\"ACAO_A_REALIZAR\"))\\\n",
    "                                               .withColumnRenamed('TARGET', 'probabilidade_religacao')\\\n",
    "                                               .drop(\"ACAO_A_REALIZAR\")\n",
    " \n",
    "    return df_lista_filtrada_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gera priorização de ligacoes com base no potencial de retorno do débito em:\n",
    " - grupo de leitura\n",
    " - logradouro\n",
    " - cdc\n",
    "\"\"\"\n",
    "def ordenacao_lista(df_lista):\n",
    "  \n",
    "  lista = df_lista\\\n",
    "  .withColumn('logradouro_completo', max(col('logradouro_completo'))\\\n",
    "                                    .over(Window.partitionBy('logradouro_id')))\\\n",
    "  .withColumn('potencial_retorno_cdc', sqrt('total_debito_cdc')*col('probabilidade_religacao'))\\\n",
    "  .withColumn('potencial_retorno_grupo', sum(col('potencial_retorno_cdc'))\\\n",
    "                                         .over(Window.partitionBy('grupo_leitura_id')))\\\n",
    "  .withColumn('potencial_retorno_logradouro', sum(col('potencial_retorno_cdc'))\\\n",
    "                                              .over(Window.partitionBy('logradouro_id')))\\\n",
    "  .withColumn('debito_total_grupo',round(sum(col('total_debito_cdc'))\\\n",
    "                                         .over(Window.partitionBy('grupo_leitura_id')),2))\\\n",
    "  .withColumn('debito_total_logradouro', round(sum(col('total_debito_cdc'))\\\n",
    "                                               .over(Window.partitionBy('logradouro_id')),2))\\\n",
    "  .withColumn('hit_total_grupo', round(sum(col('hit_cdc'))\\\n",
    "                                       .over(Window.partitionBy('grupo_leitura_id')),2))\\\n",
    "  .withColumn('hit_total_logradouro', round(sum(col('hit_cdc'))\\\n",
    "                                            .over(Window.partitionBy('logradouro_id')),2))\\\n",
    "  .orderBy(desc('potencial_retorno_grupo'),\\\n",
    "           desc('potencial_retorno_logradouro'),\\\n",
    "           desc('potencial_retorno_cdc'))\n",
    " \n",
    "  lista_final = lista.withColumnRenamed('cdc', 'ligacao')\\\n",
    "                     .drop('grupo_leitura_id', 'logradouro_id')\n",
    "\n",
    "  return lista_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gerencia a priorizacao com base no modelo selfcures e o modelo de religacao, para fiscalizacao e corte\n",
    "\"\"\"\n",
    "\n",
    "def get_priorizacao_proximidade(df_lista, obj = \"cortar\", n_cidade=\"\", n_unidade = \"\"):\n",
    "  \n",
    "  if (obj == \"fiscalizar\"):\n",
    "    lista = df_lista.select('cdc','grupo_leitura', 'grupo_leitura_id', 'setor_leitura',\\\n",
    "                            'logradouro_id', 'logradouro_completo','total_debito_cdc',\\\n",
    "                            'total_faturas_debidas_cdc','hit_cdc', 'acao_sugerida', 'probabilidade_religacao')\n",
    "  elif (obj == \"cortar\"):\n",
    "    lista = df_lista.select('cdc','grupo_leitura', 'grupo_leitura_id', 'setor_leitura',\\\n",
    "                            'logradouro_id', 'logradouro_completo','total_debito_cdc', 'total_faturas_debidas_cdc',\\\n",
    "                            'hit_cdc')\n",
    "    \n",
    "  \n",
    "   #################### APLICANDO MODELO DE RELIGACAO ########################\n",
    "  if (obj == \"cortar\"):\n",
    "    lista_modelo = aplica_modelo_preditivo_religa(lista, n_cidade,  n_unidade)\n",
    "  else:\n",
    "    lista_modelo = lista\n",
    "  \n",
    "  ############################################################################\n",
    "\n",
    "  ##################### CONSTRUINDO LISTA ALTERNATIVA ########################\n",
    "  \n",
    "  lista_final = ordenacao_lista(lista_modelo)\n",
    "  \n",
    "  ############################################################################\n",
    "  \n",
    "  return lista_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def geracao_listas_handler(df_predictions, periodo_inicial, periodo_final,\n",
    "                           n_cidade = \"\",\n",
    "                           n_unidade = \"\",\n",
    "                           dir_path = \"mnt/datalake-ambiental/output/modelo_self_cure\",\n",
    "                           prefix_lista = \"sugestoes_modeloselfcures_paracampo\"):\n",
    "  \n",
    "  timezone = pytz.timezone('America/Sao_Paulo')\n",
    "  data_hora_listas = datetime.now(tz = timezone).strftime('%Y-%m-%d %H:%M:%S')\n",
    "  df_cadastros = spark.read.table('transient.cadastros_modelo').cache()\n",
    "  \n",
    "  # SE RENOMEIA O CLIENTE INQUILINO PARA NAO CRIAR UM ERRO DE CODIGO NA HORA DE USAR A FUNCAO DE VERIFICACAO DE CLIENTES ATUAIS\n",
    "  df_predictions = df_predictions.withColumnRenamed('idclienteinquilino', 'preds_idclienteinquilino')\n",
    "  \n",
    "  # TRAZEMOS INFORMACOES DE CADASTROS QUE IRAO NOS AJUDAR NA EXECUCAO DE FILTROS, REGRAS E AGREGACOES EM FUNCOES POSTERIORES\n",
    "  predicoes_cadastros = df_predictions.alias('preds').join(df_cadastros.alias('cadastro'),\\\n",
    "                                                           [df_predictions.cdc == df_cadastros.cdc], 'LEFT')\\\n",
    "                                                    .select('preds.*', 'cadastro.tipo_faturamento', 'cadastro.tipo_faturamento_id',\\\n",
    "                                                            'cadastro.idclienteinquilino','cadastro.ativo_juridico',\\\n",
    "                                                            'cadastro.situacao_ligacao_id')\\\n",
    "                                                    .withColumnRenamed('idclienteinquilino', 'cadas_idclienteinquilino')\n",
    "  \n",
    "  \n",
    "  ############ GERANDO OS TIPOS DE FATURAMENTO E CATEGORIAS PARA A UNIDADE DO PARAMETRO##################\n",
    "  \n",
    "  #######################################################################################################\n",
    "  \n",
    "  #################### TRANSFORMANDO IDS EM LISTA PARA APLICACAO DE FILTRO ##############################\n",
    "  sqlContext.sql(\"refresh table transient.codigos_tipo_faturamento\")\n",
    "  sqlContext.sql(\"refresh table transient.codigos_categorias\")\n",
    "  \n",
    "  df_t_faturamento = spark.read.table('transient.codigos_tipo_faturamento')\n",
    "  df_categorias = spark.read.table('transient.codigos_categorias')\n",
    "  \n",
    "  lista_id_faturamento = list(set([row.idtipofaturamento for row in df_t_faturamento.collect()]))\n",
    "  lista_id_categorias =  list(set([row.idcategoria for row in df_categorias.collect()]))\n",
    "  ##########################################################################################################\n",
    "  \n",
    "  ##########APLICA FILTRO PARA RETIRAR CLIENTES PUBLICOS E MANTER APENAS AS LIGACOES EM SITUACAO ATIVA######\n",
    "  predicoes_cadastros  = predicoes_cadastros.where((col('tipo_faturamento_id').isin(*lista_id_faturamento))\\\n",
    "                                                   & (col('idcategoria').isin(*lista_id_categorias))\\\n",
    "                                                   & (col('situacao_ligacao_id') == 1))\n",
    "  \n",
    "  #############################################################################################################\n",
    "  \n",
    "  #SEPARAMOS OS CLIENTES QUE MORAM ATUALMENTE NAS LIGACOES QUE ENTRARAO PARA CORTE/FISCALIZACAO\n",
    "  lista_devedor_diferente_morador_atual, devedores_atuais = get_cdcs_id_corrente(predicoes_cadastros)\n",
    "  \n",
    "  #MANTEMOS APENAS QUEM NAO ESTA EM PROCESSO JURIDICO\n",
    "  devedores_atuais_ = devedores_atuais.where((~(col(\"ativo_juridico\") == \"S\")) | (col(\"ativo_juridico\").isNull()))\n",
    "  \n",
    "  #APLICAMOS AS FUNCOES PARA SEGMENTAR SELFCURES, NON-SELFCURES PARA CAMPO E CORTADOS A MAIS DE 90 DIAS (ESSA ULTIMA E UMA LISTA APENAS PARA ANALISE)\n",
    "  self_cure_list = get_self_cures(devedores_atuais_)\n",
    "  #cortados_mais_90_dias_list = get_cortados_mais_90_dias(devedores_atuais_)\n",
    "  non_selfcures_paracorte_list = get_nao_self_cures_paracortar(devedores_atuais_)\n",
    "  non_selfcures_parafiscalizar_list = get_lista_parafiscalizar(n_cidade = n_cidade, n_unidade = n_unidade)\n",
    "  nsc_paracortar_list = get_priorizacao_proximidade(non_selfcures_paracorte_list, n_cidade = n_cidade, n_unidade = n_unidade)\n",
    "  \n",
    "  flag = 1\n",
    "  if (not non_selfcures_parafiscalizar_list is None):\n",
    "    nsc_parafiscalizar_list = get_priorizacao_proximidade(non_selfcures_parafiscalizar_list, obj = \"fiscalizar\", n_cidade = n_cidade, n_unidade = n_unidade)\n",
    "  else:\n",
    "    flag = 0\n",
    "  \n",
    "  #CONSTRUINDO O NOME EXCEL DAS LISTAS\n",
    "  \n",
    "  arquivo_campo = \\\n",
    "  os.path.join('/dbfs',dir_path,n_cidade,\"listas\",prefix_lista+\"_\"+n_unidade+\"_\"+n_cidade+\"_\"+periodo_inicial+\"_\"+periodo_final+\"_exec_\"+data_hora_listas.replace(\":\",\"_\") + \".xls\")\n",
    " \n",
    "  \n",
    "  \n",
    "  #SALVANDO EM EXCEL\n",
    "  \n",
    "  with pd.ExcelWriter(arquivo_campo) as writer:\n",
    "    nsc_paracortar_list.toPandas().to_excel(writer, sheet_name='para_corte')\n",
    "    if (flag == 1):\n",
    "      nsc_parafiscalizar_list.toPandas().to_excel(writer, sheet_name='para_fiscalizacao')\n",
    "    self_cure_list.toPandas().to_excel(writer, sheet_name='self_cures')\n",
    "    #cortados_mais_90_dias_list.toPandas().to_excel(writer, sheet_name='cortados_mais_90_dias')\n",
    " \n",
    "  return arquivo_campo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executor Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>&apos;global_view_creator_finalizado_com_sucesso&apos;\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = spark._jvm.org.apache.log4j.LogManager.getLogger('gerador_base')\n",
    "\n",
    "\n",
    "#########################################GERACAO DE TABELAS BASE################################################\n",
    "dbutils.notebook.run(\"utilidades\", 500, {\"v_output\": \"codigos_cidade_unidadeoperacional\",\\\n",
    "                                         \"id_unidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                         \"id_cidade\": dbutils.widgets.get(\"idcidade\")})\n",
    "\n",
    "dbutils.notebook.run(\"gerador_views_genericas\", 500, {\"a_output\": \"cadastros\",\\\n",
    "                                                                    \"idunidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                                                    \"idcidade\": dbutils.widgets.get(\"idcidade\")})\n",
    "\n",
    "dbutils.notebook.run(\"gerador_views_genericas\", 500, {\"a_output\": \"processos\",\\\n",
    "                                                                    \"idunidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                                                    \"idcidade\": dbutils.widgets.get(\"idcidade\")})\n",
    "\n",
    "dbutils.notebook.run(\"utilidades\", 500, {\"v_output\": \"codigos_tipo_faturamento\",\\\n",
    "                                           \"id_unidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                           \"id_cidade\": dbutils.widgets.get(\"idcidade\")})\n",
    "  \n",
    "dbutils.notebook.run(\"utilidades\", 500, {\"v_output\": \"codigos_categorias\",\\\n",
    "                                            \"id_unidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                             \"id_cidade\": dbutils.widgets.get(\"idcidade\")})\n",
    "\n",
    "dbutils.notebook.run(\"gerador_views_genericas\", 500, {\"a_output\": \"cortes\",\\\n",
    "                                                      \"idunidade_operacional\": dbutils.widgets.get(\"idunidade_operacional\"),\\\n",
    "                                                      \"idcidade\": dbutils.widgets.get(\"idcidade\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "################################# REFRESHING DAS TABELAS GERADAS ##############################\n",
    "sqlContext.sql(\"refresh table transient.codigos_cidade_unidadeoperacional\")\n",
    "sqlContext.sql(\"refresh table transient.codigos_tipo_faturamento\")\n",
    "sqlContext.sql(\"refresh table transient.codigos_categorias\")\n",
    "sqlContext.sql(\"refresh table transient.cadastros_modelo\")\n",
    "sqlContext.sql(\"refresh table transient.processos_modelo\")\n",
    "###############################################################################################\n",
    "\n",
    "################################# IDENTIFICANDO NOMES DE CIDADE E UNIDADE ######################\n",
    "n_unidade_cidade = spark.read.table('transient.codigos_cidade_unidadeoperacional')\n",
    "\n",
    "nome_uoperacional1 =\"\".join(n_unidade_cidade.collect()[0].unidadeoperacional.lower().split(\" \"))\n",
    "nome_cidade1 =\"\".join(n_unidade_cidade.collect()[0].cidade.lower().split(\" \"))\n",
    "\n",
    "nome_uoperacional2 =\"_\".join(n_unidade_cidade.collect()[0].unidadeoperacional.lower().split(\" \"))\n",
    "nome_cidade2 =\"_\".join(n_unidade_cidade.collect()[0].cidade.lower().split(\" \"))\n",
    "###############################################################################################\n",
    "\n",
    "################################# CARREGANDO PREDICOES DO DIA #################################\n",
    "nome_tabela_predictions  = \"modelos_preditivos.\"+ nome_uoperacional1 +\"_\" + nome_cidade1+ \"_vf_predictions_execucao_noturna\"\n",
    "\n",
    "df_predictions = spark.read.table(nome_tabela_predictions)\n",
    "###############################################################################################\n",
    "\n",
    "################################# GERANDO LISTAS #################################################\n",
    "data_execucao = datetime.now()\n",
    "periodo_inicial = data_execucao.replace(day=1) + relativedelta(months=-8)\n",
    "periodo_final = data_execucao + relativedelta(days = -35)\n",
    "periodo_inicial = periodo_inicial.strftime('%Y-%m-%d')\n",
    "periodo_final = periodo_final.strftime('%Y-%m-%d')\n",
    "arquivo_campo= geracao_listas_handler(df_predictions, periodo_inicial, periodo_final,\\\n",
    "                                      n_cidade=nome_cidade2, n_unidade = nome_uoperacional2)\n",
    "###############################################################################################\n",
    "\n",
    "######################### SALVANDO O NOME DO ARQUIVO PARA ANEXAR NO E-MAIL ###################\n",
    "data_para_tabela = {'nome_lista': [arquivo_campo],\n",
    "                      'unidade': [\"maua\"]}\n",
    "df1 = pd.DataFrame(data_para_tabela)\n",
    "df2 = spark.createDataFrame(df1)\n",
    "df2.write.mode(\"append\").insertInto(\"transient.listas_para_email\")\n",
    "###############################################################################################                                                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "name": "gerador_listas_campo",
  "notebookId": 2783885934615706
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
